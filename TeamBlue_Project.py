# -*- coding: utf-8 -*-
"""Global ai hub Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sAiXy-QZhKwimZfcQAQ34dMw5N9TN26y

# Kütüphaneleri İndirme

Bu kısımda kullanacağımız veri setlerini indirdiğimiz kısım.
"""

!pip install librosa
!pip install opencv-python
!pip install -q keras

"""# Veri Setini İnceleme
Veri setimizi önceden bilgisayarımızı indirmiştik. İndirdiğim veri setini "zip" formatına çeviriyorum ve google drive'ıma yüklüyorum. Yüklediğim veri setini bu kısımda unzip ile "/content" yolunun içindeki oluşturduğum bir klasörün içerisine ayıklıyorum.

Tabi daha öncesinden drive'ınız ile colab entegre etmeyi unutumayın!

Eğer veri setini indirmek istiyor iseniz aşağıda bıraktığım linkten indirebilirsiniz.

Dataset: https://urbansounddataset.weebly.com/urbansound8k.html

"""

!unzip "/content/drive/MyDrive/UrbanSound.zip" -d "/content/UrbanSound/"

"""Bu kısımda kütüphanelerimi sisteme belirtiyorum."""

import librosa
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import IPython.display as ipd
from PIL import Image
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout
from tensorflow.keras.utils import to_categorical 

from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.model_selection import GridSearchCV

from sklearn.preprocessing import MinMaxScaler

"""Pandas(pd) kütüphanem ile data setimi okuyorum ve içerisinindeki verilerimiz göz atıyoruz."""

# Okuma kısmı
data = pd.read_csv("/content/UrbanSound/UrbanSound8K/metadata/UrbanSound8K.csv")
# Veri setimiz
data.head(10)

"""".info" ile veri seti içerimizdeki verilerin kolonlarına, türlerine ve ne kadar veri içerdiğine bakıyoruz."""

data.info()

"""Veri setimizin shape'ine bakıyorum. (8732, 8)'lik bir matristen oluşuyor."""

print(data.shape)

"""Veri seti içerisindeki "classID" kolonun içerisinde olan değerler."""

data["classID"].unique()

"""Veri setinin "classID" kolonun içerisindeki veriler neler olduğuna ve ne kadar olduklarını gösterdim."""

data["classID"].value_counts()

"""Veri setinin "class" kolonun içerisindeki veriler neler olduğuna ve ne kadar olduklarını gösterdim."""

data["class"].value_counts()

"""Veri setimizin içerisinde bulunan kolonlar."""

data["class"].unique()

"""Readme kısmının içerisinden aldığım bu kısım sayılar classID içerinde olan değerler, numaraların karşısındaki isimler ise sayılara denk gelen isimlerdir. Bu kısımda hangi numaranın hangi isme denk geldiğini gösterdim.

* classID:<br>
A numeric identifier of the sound class:<br>
0 = air_conditioner<br>
1 = car_horn<br>
2 = children_playing<br>
3 = dog_bark<br>
4 = drilling<br>
5 = engine_idling<br>
6 = gun_shot<br>
7 = jackhammer<br>
8 = siren<br>
9 = street_music
"""

classes = data.groupby("classID")["class"].unique()
classes

"""## Veri Setinin Görselleştirilmesi
Bu kısımda veri setimizin içerisindeki ses dosyalarını resim olarak ve daha sonra ses olarak sizlere göstereceğiz.

Veri setimin içerisinden rastgele seçtiğim bir ses dosyasını gri formatta görselleştirdim ve sesini daha soraki kodda belirttim.
"""

# Kütphanin belirtilmesi
import librosa.display
# ses dosyasının librosa kütüphanesi ile okunması
y, sr = librosa.load("/content/UrbanSound/UrbanSound8K/audio/fold1/101415-3-0-2.wav")

# Matplotlib ile ses dosyasının görselleştirme kısmı
plt.figure(figsize = (10,5))
D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref = np.max)
img = librosa.display.specshow(D, cmap='gray_r')
plt.colorbar(img,format="%+2.f dB")

# Yukarıdaki ses dosyasının sesi!
ipd.Audio(y,rate=sr)

# ses dosyasının librosa kütüphanesi ile okunması
y, sr = librosa.load("/content/UrbanSound/UrbanSound8K/audio/fold5/100263-2-0-36.wav")

# Matplotlib ile ses dosyasının görselleştirme kısmı
plt.figure(figsize = (20,10))
D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref = np.max)
plt.subplot(4, 2, 1)
librosa.display.specshow(D, y_axis = "linear")
plt.colorbar(format='%+2.0f dB')

# Yukarıdaki ses dosyasının sesi!
ipd.Audio(y,rate=sr)

# ses dosyasının librosa kütüphanesi ile okunması
y, sr = librosa.load("/content/UrbanSound/UrbanSound8K/audio/fold7/101848-9-0-2.wav")

# Matplotlib ile ses dosyasının görselleştirme kısmı
plt.figure(figsize = (20,10))
D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref = np.max)
plt.subplot(4, 2, 1)
librosa.display.specshow(D, y_axis = "linear")
plt.colorbar(format='%+2.0f dB')

# Yukarıdaki ses dosyasının sesi!
ipd.Audio(y,rate=sr)

"""# Veri Setini Hazırlama
Bu kısımda veri setimizi CNN(Convolutional Neural Network) modelimizde eğitim yapmak için hazırlayacağız.

Bu kısımda spectrogram'ına ayırdığım ses dosyasının shape'ine baktım bunu yapma nedenim ilerine "128" sayısını kullanacağımdan ötürüdür.
"""

# Ses dosyasının librosa kütüphanesi okunması
dat1, sampling_rate1 = librosa.load('/content/UrbanSound/UrbanSound8K/audio/fold1/101415-3-0-2.wav')
# Ses dosyasının liborsa ile spectrogram'ına ayırma işlemi
arr = librosa.feature.melspectrogram(y=dat1, sr=sampling_rate1)
# spectrogram'ına ayrılan ses dosyasının shape'i
arr.shape

"""Veri setimizin içerisindeki ses dosyalarını spectrogram'ına ayıracağım foksiyonum. En son koddda numpy kütüphanesi ile oluşan spectrogram'ın ortalamasını alıp seksene böldüm. Bunu yapma sebebim veri setini düz spectrogram'ına ayırdığımızda bir ses dosyasının spectrogram'ı (128,1) formatına çevirmek ve seksene bölerekte normlizasyon işlemini yaptım."""

def create_pectrogram(path):
  # Ses dosyasının librosa kütüphanesi okunması
  y, sr = librosa.load(path)

  #spec_conv = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T,axis=0) Bu kısım denemedir isterseniz aşağıdaki kodları uygulamak yerine direk bu kısmı uygulaya bilirsiniz!

  # Ses dosyasının liborsa ile spectrogram'ına ayırma işlemi
  spec = librosa.feature.melspectrogram(y=y)

  # Genlik spektrogramını dB ölçekli spektrograma dönüştürün.
  spec_conv = librosa.amplitude_to_db(spec, ref = np.max)
  
  spec_mean = np.mean((spec_conv / 80.0).T, axis = 0)
  return spec_mean

"""Bu kısımda veri setimizideki her ses doyasının spectrogram'larına dönüştürüyorum ve dönüştürüdüğüm ses dosyalarının classID'lerini alıyorum bir liste içerisine."""

# Dosya içerisindeki ses dosyalarımızı sepctogramlarına ayırıyoruz ve classID'leri ile birleştiriyoruz.
# Listelerim
spectrogram = []
classid = []

# Ayırştırma işleminin olduğu kısım
for i in range(data.shape[0]):
  # Ses dosyasının yolunu saptıyorum
  file_name = "/content/UrbanSound/UrbanSound8K/audio/fold" + str(data["fold"][i]) + "/" + data["slice_file_name"][i]
  label = data["classID"][i]
  # Ses dosyasının spectrogram'ını hazırladığım fonksiyon ile alıyorum.
  spec_conv = create_pectrogram(file_name)

  # Listelerin içerisinde eklediğim kısım
  spectrogram.append(spec_conv)
  classid.append(label)

# Bir ses dosyaısının spectrogram'ı
spectrogram[0]

# Bir ses dosyasının classID'si
classid[0:10]

"""Veri seti içerisindeki ses dosyalarının spectrogram'larını ve classID'lerini ayrı bi şekilde aldıktan sonra, aldığım bu verileri pandas kütüphanesi ile dataframe haline çeviriyorum."""

# spectrogram ve classID'nin dictionary kısımı
new_data = {"goruntu" : spectrogram , "etiket" : classid}

# Bu kısımda dataframe aldığım kısım
new_data = pd.DataFrame(new_data)

new_data.head(10)

data.shape[0]

"""Bu kısımda new_data array formatına çevirdik ve transpozunu aldım."""

data_last = np.array(new_data)
data_last = data_last.transpose()

"""Bu kısımda X ve Y kısımlarını olşturudum."""

X_ = data_last[0]
Y = data_last[1]
print(X_.shape)
print(Y.shape)

X_[0]

# X dosyasının shape'ini değiştiriyorum.
X = np.empty([data.shape[0], 128])
for i in range(data.shape[0]):
  X[i] = (X_[i])

# Y dosyasının shape'ini değiştiriyorum.
Y = to_categorical(Y)

print(X.shape)
print(Y.shape)

"""Bu kısımda oluşturduğum X ve Y verilerini kullanarak train ve test olarak ayırıyorum."""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)

print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

"""CNN modelimizin için shape'lerini son olarak ayarlıyorum."""

X_train = X_train.reshape(X_train.shape[0], 16, 8, 1)
X_test = X_test.reshape(X_test.shape[0], 16, 8, 1)

"""# CNN(Convolutional Neural Network)
Bu bölümde modelimizi Keras kütüphanimiz ile oluşturacağız. Modelimizi oluşturduktan sonra hazırladığımız veri seti ile eğitim gerçekleştiriyoruz. Son olarakta eğitim sonuçlarını görselleştireceğiz.

## Model Hazırlanaması
Bu kısımda CNN modelimizi oluşturuyoruz.
"""

Model = Sequential()

Model.add(Conv2D(32, (3,3), padding = "same", activation = "relu", input_shape = (16, 8, 1)))
Model.add(MaxPool2D(pool_size=(2, 2)))

Model.add(Conv2D(64, (3,3), padding = "same", activation = "relu",))
Model.add(MaxPool2D(pool_size=(2, 2)))

Model.add(Conv2D(128, (3, 3), padding = "same", activation = "relu"))
Model.add(MaxPool2D(pool_size=(2, 2)))

Model.add(Conv2D(256, (3, 3), padding = "same", activation = "relu"))
Model.add(Dropout(0.1))
Model.add(Flatten())
Model.add(Dense(1024, activation = "tanh"))
Model.add(Dense(10, activation = "softmax"))

Model.compile(optimizer = "Adam", loss = 'categorical_crossentropy', metrics = ['accuracy'])

# Hazırladığımız modelin gösterimi

Model.summary()

"""# Model Ile Eğitim
Bu kısımda modelimiz ve hazırladığımız veri seti ile eğitim gerçekleştireceğiz.
"""

Epoch = 300
batch_size = 250

hist =  Model.fit(X_train, Y_train, epochs = Epoch, batch_size = batch_size, validation_data = (X_test, Y_test))

"""# Sonuçlar ve Görselleştirme
Eğitim sonuçlarımızı görelleştireğiz.

Bu kısımda loss ve Accuracy değerlerimi matplotlib kütüphanesi ile görselleştireceğim.
"""

# Accuracy ve Validation Accuracy
plt.plot(range(Epoch), hist.history["accuracy"], color = "blue" , label = "Accuracy")
plt.plot(range(Epoch), hist.history["val_accuracy"], color = "red",  label = "Validation Accuracy")

plt.xlabel("Number Of Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# Loss ve Validation Loss
plt.plot(range(Epoch), hist.history["loss"], color = "green" , label = "Loss")
plt.plot(range(Epoch), hist.history["val_loss"], color = "black",  label = "Validation Loss")
plt.xlabel("Number Of Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

"""## Model ile Tahmin
Eğittiğimiz model ile x_test verilerini kullanarak bir tahmin yapacağız.
"""

# Tahmin etme işlemleri ve sonuçlarım
predictions = Model.predict(X_test)
score = Model.evaluate(X_test, Y_test)
print("Loss : {} Accuracy: {} ".format(score[0], score[1]))

# Tahmin değerlerim
preds = np.argmax(predictions, axis = 1)
preds

# Tahmin değerlerimin Dataframe ile gösterimi
result = pd.DataFrame(preds)
result.head(10)